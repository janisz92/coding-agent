coding-agent: opis techniczny dla AI (jak działa, funkcje, kod)

Streszczenie
- CLI uruchamia pętlę agenta korzystającą z OpenAI Responses API i narzędzi do pracy na plikach w repo.
- Agent używa sandboxu ścieżek (denylista, limity rozmiarów, blokada path traversal).
- Na starcie tworzy snapshot .agent_baseline.json do późniejszego code review (lista zmian, diffy).
- Komunikacja i wywołania narzędzi są logowane do agent.raw.txt. Po zakończeniu generowany jest lokalny git diff do agent.diff.txt (jeśli repo to git).

Wymagane środowisko
- Node.js >= 18
- Zmienna OPENAI_API_KEY (opcjonalnie OPENAI_MODEL – domyślnie „gpt-5”).

Uruchomienie (CLI)
- Polecenie:
  - npm run dev -- edit  "<OPIS>" --repo <ścieżka>
- OPIS: zadanie w naturalnym języku (agent ma je zrealizować modyfikując repo narzędziami).
- --repo: katalog repo, w którym agent ma wykonywać operacje.

Przepływ działania (wysoki poziom)
1) CLI (src/cli.ts) parsuje argumenty, buduje task (zadanie) oraz repoRoot, uruchamia runAgent.
2) runAgent (src/agent/run.ts):
   - Ładuje prompt systemowy z resources/promts/codeAgentPromt.txt.
   - Tworzy snapshot bazowy repo (.agent_baseline.json) – zapisuje zawartość mniejszych plików (<= maxReadBytes) lub tylko rozmiar.
   - Inicjalizuje RepoTools (zestaw narzędzi dla modelu) z polityką sandboxa (src/agent/security.ts).
   - Wysyła do Responses API: system + user, udostępnia specyfikacje narzędzi.
   - Pętla: odbiera function_call, wykonuje narzędzia, odsyła wyłącznie function_call_output (z call_id), używa previous_response_id.
   - Ogranicza liczbę wywołań narzędzi (domyślnie 50). Wszystko loguje do agent.raw.txt.
   - Po zakończeniu próbuje wykonać git diff i zapisuje wynik do agent.diff.txt.

Narzędzia (RepoTools – src/agent/tools.ts)
- list_files(prefix?, limit?) → { files[], total }
- read_file(path) → { path, bytes, content } [wymaga odczytu przed zapisem]
- write_file(path, content) → { path, bytes } [wymaga pełnej treści; limit rozmiaru]
- delete_file(path) → { path, deleted, reason? }
- search_in_files(query, prefix?, limit_files?, limit_matches?) → { query, matches[], scanned_files }
- get_baseline_info() → { created_at, files, maxReadBytes }
- list_changed_files(prefix?, limit?) → { baseline_files, current_files, added[], deleted[], modified[] }
- read_file_original(path) → { path, existed, bytes?, content? }
- diff_file_against_original(path, max_lines?) → { path, status, summary, diff_text?, note? }

Polityka bezpieczeństwa (src/agent/security.ts)
- Denylista katalogów: .git, node_modules, dist
- Denylista plików: .env
- Denylista rozszerzeń: .pem, .key
- Blokada path traversal: operacje wyłącznie wewnątrz repoRoot (resolveInRepo), ścieżki normalizowane do POSIX w relPath.
- Limity rozmiarów: read_file (<= maxReadBytes), write_file (<= maxWriteBytes).
- Listowanie plików (listFilesRecursive) respektuje denylistę i limit maks. liczby plików.

Logowanie (src/agent/log.ts)
- agent.raw.txt – linie tekstowe i JSON (meta, request/response modelu, wywołania/rezultaty narzędzi).
- agent.diff.txt – zapis lokalnego git diff po zakończeniu pętli.

Struktura repo (główne pliki)
- resources/promts/codeAgentPromt.txt – prompt systemowy (reguły pracy agenta).
- src/cli.ts – uruchamia pętlę agenta z argumentów CLI.
- src/openai.ts – klient OpenAI (wymaga OPENAI_API_KEY).
- src/agent/run.ts – pętla rozmowy z modelem + integracja narzędzi + baseline + logowanie + git diff.
- src/agent/tools.ts – implementacja narzędzi file I/O i narzędzi review (baseline/diffy).
- src/agent/security.ts – sandbox ścieżek (denylista, path traversal, listowanie).
- src/agent/log.ts – logger do plików.
- tests/*.ts – testy bezpieczeństwa i narzędzi.

Uwagi implementacyjne
- W Responses API wykorzystywane są: tools (spec funkcji), previous_response_id oraz przekazywanie TYLKO function_call_output (bez ponownego odsyłania samych function_call – inaczej 400 Duplicate item found).
- Snapshot baseline jest tworzony automatycznie przy starcie runAgent.
- Limit równoległości narzędzi: agent wywołuje je sekwencyjnie w pętli (nie ma równoległości w implementacji RepoTools.dispatch).

Kod źródłowy (pełna treść kluczowych plików)

=== package.json ===
{
  "name": "coding-agent",
  "private": true,
  "type": "module",
  "scripts": {
    "dev": "tsx src/cli.ts",
    "test": "node --import tsx --test"
  },
  "dependencies": {
    "dotenv": "^16.4.5",
    "openai": "^4.0.0"
  },
  "devDependencies": {
    "tsx": "^4.19.2",
    "typescript": "^5.5.4"
  },
  "engines": {
    "node": ">=18"
  }
}

=== tsconfig.json ===
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "ES2022",
    "moduleResolution": "Bundler",
    "allowImportingTsExtensions": true,
    "strict": true,
    "skipLibCheck": true,
    "noEmit": true,
    "types": ["node"]
  },
  "include": ["src", "tests"]
}

=== resources/promts/codeAgentPromt.txt ===
Jesteś wyspecjalizowanym agentem do edycji repozytorium kodu, działającym wyłącznie poprzez narzędzia (tool calling).

ROLA:
Twoim zadaniem jest precyzyjna, minimalna i bezpieczna modyfikacja kodu zgodnie z poleceniem użytkownika.

ZASADY NADRZĘDNE:
1. Zawsze używaj read_file przed jakąkolwiek modyfikacją pliku.
2. Każda zmiana musi być poprzedzona analizą istniejącego kodu.
3. Minimalizuj zakres zmian – nie wykonuj refactorów ani masowego formatowania, jeśli nie jest to wymagane.
4. Przy write_file zawsze podawaj pełną, nową zawartość pliku.
5. Nie wykonuj poleceń systemowych ani shellowych.
6. Do interakcji z repozytorium używaj wyłącznie dostępnych narzędzi.

OGRANICZENIA BEZPIECZEŃSTWA:
7. Pracujesz wyłącznie w obrębie repozytorium wskazanego przez --repo.
8. Path traversal (np. ../) jest zabroniony.
9. Nie czytaj ani nie zapisuj następujących ścieżek i plików:
   - .git/
   - node_modules/
   - dist/
   - .env
   - *.pem
   - *.key

ZASADY PRACY Z KODEM:
10. Jeśli nie znasz struktury repozytorium, użyj list_files.
11. Jeśli musisz znaleźć konkretny fragment kodu, użyj search_in_files lub list_files + read_file.
12. Zachowuj istniejące konwencje kodu, styl i architekturę.
13. Nie wprowadzaj zmian wykraczających poza zakres zadania użytkownika.
14. Nie obniżaj bezpieczeństwa ani nie zmieniaj publicznych kontraktów API bez wyraźnego polecenia.

STRATEGIA DZIAŁANIA:
15. Działaj sekwencyjnie: analiza → minimalna zmiana → zapis.
16. Każda modyfikacja musi mieć jednoznaczne uzasadnienie w kontekście zadania.

CEL:
Zrealizuj polecenie użytkownika w sposób precyzyjny, minimalnie inwazyjny, bezpieczny i w pełni kontrolowany przez narzędzia.

=== src/openai.ts ===
import OpenAI from "openai";

/**
 * Minimalny klient OpenAI.
 * Wymaga zmiennej OPENAI_API_KEY.
 */
export const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

=== src/cli.ts ===
import "dotenv/config";
import path from "node:path";

import { runAgent } from "./agent/run.ts";

function getArgValue(argv: string[], name: string): string | undefined {
  const idx = argv.indexOf(name);
  return idx === -1 ? undefined : argv[idx + 1];
}

function usage() {
  console.log(`
Użycie:
  npm run dev -- edit "<OPIS>" --repo <ścieżka>

Opis:
  edit uruchamia agentową pętlę tool-calling.
  Agent czyta i zapisuje pliki bezpośrednio (bez patchy jako mechanizmu zmian),
  loguje przebieg do agent.raw.txt oraz zapisuje raport git diff do agent.diff.txt (jeśli możliwe).
`);
}

async function main() {
  const cmd = process.argv[2];
  const repoRoot = path.resolve(getArgValue(process.argv, "--repo") ?? process.cwd());

  if (!cmd) {
    usage();
    process.exitCode = 1;
    return;
  }

  const normalizedCmd = cmd.toLowerCase();
  const isEdit = normalizedCmd === "edit";

  if (!isEdit) {
    usage();
    process.exitCode = 1;
    return;
  }

  // Task to wszystko pomiędzy komendą a --repo
  const repoIdx = process.argv.indexOf("--repo");
  const taskParts = repoIdx === -1 ? process.argv.slice(3) : process.argv.slice(3, repoIdx);
  const task = taskParts.join(" ").trim();

  if (!task) {
    console.error("[agent] ERROR: Brak opisu zadania.");
    usage();
    process.exitCode = 1;
    return;
  }

  console.log("[agent] Working (tool-calling loop)...");
  await runAgent({ repoRoot, task, model: process.env.OPENAI_MODEL ?? "gpt-5", maxToolCalls: 50 });

  console.log("[agent] Done.");
  console.log(`- Log: ${path.join(repoRoot, "agent.raw.txt")}`);
  console.log(`- Diff: ${path.join(repoRoot, "agent.diff.txt")} (jeśli git diff działa)`);
  console.log("Przejrzyj zmiany w VS Code → Source Control.");
}

main().catch((e: any) => {
  console.error("[agent] ERROR:", e?.stack ?? e?.message ?? String(e));
  process.exitCode = 1;
});

=== src/agent/log.ts ===
import fs from "node:fs";
import path from "node:path";

export class AgentLogger {
  private readonly rawPath: string;

  constructor(private readonly repoRoot: string) {
    this.rawPath = path.join(repoRoot, "agent.raw.txt");
  }

  initNewRun(meta: { task: string; model: string; startedAt: string }) {
    this.appendLine("=== AGENT RUN START ===");
    this.appendJSON({ type: "meta", ...meta });
  }

  appendLine(line: string) {
    fs.appendFileSync(this.rawPath, line + "\n", "utf8");
  }

  appendJSON(obj: any) {
    const line = JSON.stringify(obj);
    fs.appendFileSync(this.rawPath, line + "\n", "utf8");
  }

  saveDiffText(diffText: string) {
    const outPath = path.join(this.repoRoot, "agent.diff.txt");
    fs.writeFileSync(outPath, diffText, "utf8");
    return outPath;
  }
}

=== src/agent/security.ts ===
import path from "node:path";
import fs from "node:fs";

export type SandboxOptions = {
  repoRoot: string;
  denyDirs: string[]; // np. [".git", "node_modules", "dist"]
  denyFilesExact: string[]; // np. [".env"]
  denyExtensions: string[]; // np. [".pem", ".key"]
  maxReadBytes: number; // np. 400_000
  maxWriteBytes: number; // np. 800_000
};

export type SafePathResult = {
  absPath: string;
  relPath: string; // zawsze POSIX ("/")
};

/**
 * Sprawdza denylistę na ścieżce relatywnej (POSIX).
 */
export function isDeniedPath(opts: SandboxOptions, relPosixPath: string): boolean {
  const p = relPosixPath.replace(/^\/+/, ""); // bez wiodących /

  // zablokuj pliki dokładne
  const base = path.posix.basename(p);
  if (opts.denyFilesExact.includes(base)) return true;

  // zablokuj rozszerzenia
  const ext = path.posix.extname(base).toLowerCase();
  if (ext && opts.denyExtensions.map((e) => e.toLowerCase()).includes(ext)) return true;

  // zablokuj katalogi na dowolnym poziomie
  const segments = p.split("/");
  for (const seg of segments) {
    if (opts.denyDirs.includes(seg)) return true;
  }

  return false;
}

/**
 * Normalizuje ścieżkę i blokuje path traversal.
 * Zwraca relPath (POSIX) i absPath.
 */
export function resolveInRepo(opts: SandboxOptions, userPath: string): SafePathResult {
  const repoAbs = path.resolve(opts.repoRoot);
  const candidateAbs = path.resolve(repoAbs, userPath);

  const relFromRepo = path.relative(repoAbs, candidateAbs);

  // Blokada wyjścia poza repo
  const traversal =
    relFromRepo === "" ||
    relFromRepo === "." ||
    relFromRepo === ".." ||
    relFromRepo.startsWith(".." + path.sep) ||
    relFromRepo.includes(path.sep + ".." + path.sep);

  if (traversal) {
    throw new Error(`Path traversal blocked: "${userPath}"`);
  }

  const relPosix = relFromRepo.replaceAll(path.sep, "/");
  if (!relPosix || relPosix.trim() === "") {
    throw new Error(`Invalid path: "${userPath}"`);
  }

  if (isDeniedPath(opts, relPosix)) {
    throw new Error(`Access denied by policy: "${relPosix}"`);
  }

  return { absPath: candidateAbs, relPath: relPosix };
}

export function ensureParentDirExists(fileAbsPath: string): void {
  const dir = path.dirname(fileAbsPath);
  fs.mkdirSync(dir, { recursive: true });
}

/**
 * Bezpieczne listowanie plików w repo (z ignorowaniem denylist).
 * Zwraca relatywne ścieżki POSIX.
 */
export function listFilesRecursive(opts: SandboxOptions, maxFiles = 5000): string[] {
  const repoAbs = path.resolve(opts.repoRoot);
  const results: string[] = [];

  function walk(dirAbs: string) {
    if (results.length >= maxFiles) return;

    let entries: fs.Dirent[];
    try {
      entries = fs.readdirSync(dirAbs, { withFileTypes: true });
    } catch {
      return;
    }

    for (const e of entries) {
      if (results.length >= maxFiles) return;

      const childAbs = path.join(dirAbs, e.name);
      const rel = path.relative(repoAbs, childAbs).replaceAll(path.sep, "/");

      if (!rel || isDeniedPath(opts, rel)) continue;

      if (e.isDirectory()) {
        walk(childAbs);
      } else if (e.isFile()) {
        results.push(rel);
      }
    }
  }

  walk(repoAbs);
  return results.sort();
}

=== src/agent/tools.ts ===
import fs from "node:fs";
import path from "node:path";
import {
  SandboxOptions,
  listFilesRecursive,
  resolveInRepo,
  ensureParentDirExists,
} from "./security.ts";

export type ToolName =
  | "list_files"
  | "read_file"
  | "write_file"
  | "delete_file"
  | "search_in_files"
  | "get_baseline_info"
  | "list_changed_files"
  | "read_file_original"
  | "diff_file_against_original";

export type ToolCall = {
  name: ToolName;
  arguments: any;
};

export type ToolResult = {
  ok: boolean;
  result?: any;
  error?: string;
};

const BASELINE_FILENAME = ".agent_baseline.json";

export class RepoTools {
  constructor(private readonly opts: SandboxOptions) {}

  /**
   * Specyfikacje narzędzi dla modelu (function calling).
   */
  getToolSpecs() {
    return [
      {
        type: "function",
        name: "list_files",
        description:
          "List files in the repository. Returns relative POSIX paths. Denylisted dirs/files are excluded.",
        parameters: {
          type: "object",
          additionalProperties: false,
          properties: {
            prefix: {
              type: "string",
              description: "Optional prefix filter (POSIX, e.g. 'src/' ).",
            },
            limit: {
              type: "integer",
              description: "Max number of files to return (default 2000).",
              minimum: 1,
              maximum: 5000,
            },
          },
        },
      },
      {
        type: "function",
        name: "read_file",
        description:
          "Read a text file from repo. MUST be called before modifying a file. Denylist and size limit apply.",
        parameters: {
          type: "object",
          additionalProperties: false,
          properties: {
            path: { type: "string", description: "Relative path inside repo." },
          },
          required: ["path"],
        },
      },
      {
        type: "function",
        name: "write_file",
        description:
          "Write (create/overwrite) a text file inside repo. Provide full new file content. Denylist and size limit apply.",
        parameters: {
          type: "object",
          additionalProperties: false,
          properties: {
            path: { type: "string", description: "Relative path inside repo." },
            content: { type: "string", description: "Full new file content." },
          },
          required: ["path", "content"],
        },
      },
      {
        type: "function",
        name: "delete_file",
        description:
          "Delete a file inside repo. Use only when explicitly needed. Denylist applies.",
        parameters: {
          type: "object",
          additionalProperties: false,
          properties: {
            path: { type: "string", description: "Relative path inside repo." },
          },
          required: ["path"],
        },
      },
      {
        type: "function",
        name: "search_in_files",
        description:
          "Search for a substring in text files (simple contains). Returns matches with file and line numbers. Denylist and max file size apply.",
        parameters: {
          type: "object",
          additionalProperties: false,
          properties: {
            query: { type: "string", description: "Substring to search for." },
            prefix: { type: "string", description: "Optional path prefix filter, e.g. 'src/'." },
            limit_files: { type: "integer", minimum: 1, maximum: 2000 },
            limit_matches: { type: "integer", minimum: 1, maximum: 2000 },
          },
          required: ["query"],
        },
      },
      {
        type: "function",
        name: "get_baseline_info",
        description:
          "Get metadata about the initial repository snapshot used for review (created at agent start).",
        parameters: { type: "object", additionalProperties: false, properties: {} },
      },
      {
        type: "function",
        name: "list_changed_files",
        description:
          "List added/modified/deleted files compared to the baseline snapshot (created at agent start).",
        parameters: {
          type: "object",
          additionalProperties: false,
          properties: {
            prefix: { type: "string", description: "Optional path prefix filter, e.g. 'src/'." },
            limit: { type: "integer", minimum: 1, maximum: 5000 },
          },
        },
      },
      {
        type: "function",
        name: "read_file_original",
        description:
          "Read file content from the baseline snapshot (original version at agent start).",
        parameters: {
          type: "object",
          additionalProperties: false,
          properties: {
            path: { type: "string", description: "Relative path inside repo." },
          },
          required: ["path"],
        },
      },
      {
        type: "function",
        name: "diff_file_against_original",
        description:
          "Compute a simple unified diff between current file content and the baseline (original). Returns summary and diff text.",
        parameters: {
          type: "object",
          additionalProperties: false,
          properties: {
            path: { type: "string", description: "Relative path inside repo." },
            max_lines: { type: "integer", description: "Max diff lines to include in output (default 2000).", minimum: 1, maximum: 10000 },
          },
          required: ["path"],
        },
      },
    ] as const;
  }

  async dispatch(call: ToolCall): Promise<ToolResult> {
    try {
      switch (call.name) {
        case "list_files":
          return { ok: true, result: this.listFiles(call.arguments) };
        case "read_file":
          return { ok: true, result: this.readFile(call.arguments) };
        case "write_file":
          return { ok: true, result: this.writeFile(call.arguments) };
        case "delete_file":
          return { ok: true, result: this.deleteFile(call.arguments) };
        case "search_in_files":
          return { ok: true, result: this.searchInFiles(call.arguments) };
        case "get_baseline_info":
          return { ok: true, result: this.getBaselineInfo() };
        case "list_changed_files":
          return { ok: true, result: this.listChangedFiles(call.arguments) };
        case "read_file_original":
          return { ok: true, result: this.readFileOriginal(call.arguments) };
        case "diff_file_against_original":
          return { ok: true, result: this.diffFileAgainstOriginal(call.arguments) };
        default:
          return { ok: false, error: `Unknown tool: ${(call as any).name}` };
      }
    } catch (e: any) {
      return { ok: false, error: e?.message ?? String(e) };
    }
  }

  private listFiles(args: { prefix?: string; limit?: number }) {
    const all = listFilesRecursive(this.opts, 5000);
    const prefix = (args.prefix ?? "").trim();
    let out = all;
    if (prefix) out = out.filter((p) => p.startsWith(prefix));
    const limit = Math.min(Math.max(args.limit ?? 2000, 1), 5000);
    return { files: out.slice(0, limit), total: out.length };
  }

  private readFile(args: { path: string }) {
    const { absPath, relPath } = resolveInRepo(this.opts, args.path);

    const st = fs.statSync(absPath);
    if (!st.isFile()) throw new Error(`Not a file: ${relPath}`);

    if (st.size > this.opts.maxReadBytes) {
      throw new Error(
        `File too large for read_file (${st.size} bytes > ${this.opts.maxReadBytes}): ${relPath}`
      );
    }

    const content = fs.readFileSync(absPath, "utf8");
    return { path: relPath, bytes: st.size, content };
  }

  private writeFile(args: { path: string; content: string }) {
    const { absPath, relPath } = resolveInRepo(this.opts, args.path);

    const content = args.content ?? "";
    const bytes = Buffer.byteLength(content, "utf8");
    if (bytes > this.opts.maxWriteBytes) {
      throw new Error(
        `Content too large for write_file (${bytes} bytes > ${this.opts.maxWriteBytes}): ${relPath}`
      );
    }

    ensureParentDirExists(absPath);
    fs.writeFileSync(absPath, content, "utf8");
    return { path: relPath, bytes };
  }

  private deleteFile(args: { path: string }) {
    const { absPath, relPath } = resolveInRepo(this.opts, args.path);

    if (!fs.existsSync(absPath)) {
      return { path: relPath, deleted: false, reason: "not_found" as const };
    }
    const st = fs.statSync(absPath);
    if (!st.isFile()) throw new Error(`Not a file: ${relPath}`);

    fs.unlinkSync(absPath);
    return { path: relPath, deleted: true };
  }

  private searchInFiles(args: {
    query: string;
    prefix?: string;
    limit_files?: number;
    limit_matches?: number;
  }) {
    const query = (args.query ?? "").toString();
    if (!query) throw new Error("query is required");

    const prefix = (args.prefix ?? "").trim();
    const limitFiles = Math.min(Math.max(args.limit_files ?? 800, 1), 2000);
    const limitMatches = Math.min(Math.max(args.limit_matches ?? 200, 1), 2000);

    const all = listFilesRecursive(this.opts, 5000)
      .filter((p) => (prefix ? p.startsWith(prefix) : true))
      .slice(0, limitFiles);

    const matches: Array<{ path: string; line: number; text: string }> = [];

    for (const rel of all) {
      if (matches.length >= limitMatches) break;

      const abs = path.resolve(this.opts.repoRoot, rel.replaceAll("/", path.sep));
      let st: fs.Stats;
      try {
        st = fs.statSync(abs);
      } catch {
        continue;
      }
      if (!st.isFile()) continue;
      if (st.size > this.opts.maxReadBytes) continue;

      const content = fs.readFileSync(abs, "utf8");
      if (!content.includes(query)) continue;

      const lines = content.split(/\r?\n/);
      for (let i = 0; i < lines.length; i++) {
        if (matches.length >= limitMatches) break;
        if (lines[i].includes(query)) {
          matches.push({ path: rel, line: i + 1, text: lines[i].slice(0, 400) });
        }
      }
    }

    return { query, matches, scanned_files: all.length };
  }

  private baselinePath(): string {
    return path.join(this.opts.repoRoot, BASELINE_FILENAME);
  }

  private loadBaseline(): {
    createdAt: string;
    maxReadBytes: number;
    files: Record<string, { bytes: number; content: string | null }>;
  } {
    const p = this.baselinePath();
    if (!fs.existsSync(p)) {
      throw new Error("Baseline snapshot not found. It should be created automatically at agent start.");
    }
    const raw = fs.readFileSync(p, "utf8");
    let json: any;
    try {
      json = JSON.parse(raw);
    } catch {
      throw new Error("Invalid baseline file JSON.");
    }
    if (!json || typeof json !== "object" || !json.files) {
      throw new Error("Invalid baseline format.");
    }
    return json;
  }

  private getBaselineInfo() {
    const b = this.loadBaseline();
    const count = Object.keys(b.files).length;
    return { created_at: b.createdAt, files: count, maxReadBytes: b.maxReadBytes };
  }

  private listChangedFiles(args: { prefix?: string; limit?: number }) {
    const b = this.loadBaseline();
    const baselineFiles = Object.keys(b.files);
    const currentFiles = listFilesRecursive(this.opts, 5000);

    const prefix = (args.prefix ?? "").trim();
    const filt = (p: string) => (prefix ? p.startsWith(prefix) : true);

    const baselineSet = new Set(baselineFiles);
    const currentSet = new Set(currentFiles);

    const added = currentFiles.filter((p) => !baselineSet.has(p) && filt(p));
    const deleted = baselineFiles.filter((p) => !currentSet.has(p) && filt(p));

    const modified: string[] = [];
    for (const p of currentFiles) {
      if (!baselineSet.has(p)) continue;
      if (!filt(p)) continue;
      const abs = path.resolve(this.opts.repoRoot, p.replaceAll("/", path.sep));
      let st: fs.Stats;
      try {
        st = fs.statSync(abs);
      } catch {
        continue;
      }
      const base = b.files[p];
      if (!base) continue;
      if (st.size !== base.bytes) {
        modified.push(p);
      } else if (base.content != null && st.size <= this.opts.maxReadBytes) {
        try {
          const currentContent = fs.readFileSync(abs, "utf8");
          if (currentContent !== base.content) modified.push(p);
        } catch {}
      }
    }

    const limit = Math.min(Math.max(args.limit ?? 2000, 1), 5000);
    return {
      baseline_files: baselineFiles.length,
      current_files: currentFiles.length,
      added: added.slice(0, limit),
      deleted: deleted.slice(0, limit),
      modified: modified.slice(0, limit),
    };
  }

  private readFileOriginal(args: { path: string }) {
    const { relPath } = resolveInRepo(this.opts, args.path);
    const b = this.loadBaseline();
    const base = b.files[relPath];
    if (!base) {
      return { path: relPath, existed: false };
    }
    return { path: relPath, existed: true, bytes: base.bytes, content: base.content };
  }

  private diffFileAgainstOriginal(args: { path: string; max_lines?: number }) {
    const { absPath, relPath } = resolveInRepo(this.opts, args.path);
    const b = this.loadBaseline();
    const base = b.files[relPath];

    let currentExists = fs.existsSync(absPath) && fs.statSync(absPath).isFile();

    if (!base && !currentExists) {
      return {
        path: relPath,
        status: "unchanged",
        summary: { before_bytes: 0, after_bytes: 0, added_lines: 0, removed_lines: 0 },
        note: "File did not exist in baseline and still does not exist.",
      };
    }

    const maxLines = Math.min(Math.max(args.max_lines ?? 2000, 1), 10000);

    if (!base && currentExists) {
      const content = this.safeRead(absPath, this.opts.maxReadBytes);
      const lines = content.split(/\r?\n/);
      const diff = this.buildUnifiedDiff(relPath, [], lines, maxLines);
      return {
        path: relPath,
        status: "added",
        summary: { before_bytes: 0, after_bytes: Buffer.byteLength(content, "utf8"), added_lines: lines.length, removed_lines: 0 },
        diff_text: diff,
      };
    }

    if (base && !currentExists) {
      const baseLines = (base.content ?? "").split(/\r?\n/);
      const diff = this.buildUnifiedDiff(relPath, baseLines, [], maxLines);
      return {
        path: relPath,
        status: "deleted",
        summary: { before_bytes: base.bytes, after_bytes: 0, added_lines: 0, removed_lines: baseLines.length },
        diff_text: diff,
      };
    }

    // both exist
    const baseContent = base!.content;
    if (baseContent == null) {
      const st = fs.statSync(absPath);
      const changed = st.size !== base!.bytes;
      return {
        path: relPath,
        status: changed ? "modified" : "unchanged",
        summary: { before_bytes: base!.bytes, after_bytes: st.size, added_lines: 0, removed_lines: 0 },
        note: "Original file too large for content diff; compared by size only.",
      };
    }

    const currentContent = this.safeRead(absPath, this.opts.maxReadBytes);
    const baseLines = baseContent.split(/\r?\n/);
    const curLines = currentContent.split(/\r?\n/);
    const ops = this.diffLines(baseLines, curLines);
    let added = 0;
    let removed = 0;
    for (const op of ops) {
      if (op.type === "add") added += op.lines.length;
      if (op.type === "remove") removed += op.lines.length;
    }
    const diff = this.buildUnifiedDiff(relPath, baseLines, curLines, maxLines, ops);

    return {
      path: relPath,
      status: added === 0 && removed === 0 ? "unchanged" : "modified",
      summary: {
        before_bytes: Buffer.byteLength(baseContent, "utf8"),
        after_bytes: Buffer.byteLength(currentContent, "utf8"),
        added_lines: added,
        removed_lines: removed,
      },
      diff_text: diff,
    };
  }

  private safeRead(absPath: string, limit: number): string {
    const st = fs.statSync(absPath);
    if (st.size > limit) {
      throw new Error(`File too large for diff (${st.size} bytes > ${limit}): ${absPath}`);
    }
    return fs.readFileSync(absPath, "utf8");
  }

  // Prosty LCS diff linii
  private diffLines(a: string[], b: string[]): Array<{ type: "equal" | "add" | "remove"; lines: string[] }> {
    const m = a.length;
    const n = b.length;
    const dp: number[][] = Array.from({ length: m + 1 }, () => Array(n + 1).fill(0));
    for (let i = m - 1; i >= 0; i--) {
      for (let j = n - 1; j >= 0; j--) {
        if (a[i] === b[j]) dp[i][j] = dp[i + 1][j + 1] + 1;
        else dp[i][j] = Math.max(dp[i + 1][j], dp[i][j + 1]);
      }
    }
    const ops: Array<{ type: "equal" | "add" | "remove"; lines: string[] }> = [];
    let i = 0,
      j = 0;
    while (i < m && j < n) {
      if (a[i] === b[j]) {
        this.pushOp(ops, "equal", a[i]);
        i++;
        j++;
      } else if (dp[i + 1][j] >= dp[i][j + 1]) {
        this.pushOp(ops, "remove", a[i]);
        i++;
      } else {
        this.pushOp(ops, "add", b[j]);
        j++;
      }
    }
    while (i < m) {
      this.pushOp(ops, "remove", a[i++]);
    }
    while (j < n) {
      this.pushOp(ops, "add", b[j++]);
    }
    return ops;
  }

  private pushOp(
    ops: Array<{ type: "equal" | "add" | "remove"; lines: string[] }>,
    type: "equal" | "add" | "remove",
    line: string
  ) {
    const last = ops[ops.length - 1];
    if (last && last.type === type) {
      last.lines.push(line);
    } else {
      ops.push({ type, lines: [line] });
    }
  }

  private buildUnifiedDiff(
    relPath: string,
    a: string[],
    b: string[],
    maxLines: number,
    precomputedOps?: Array<{ type: "equal" | "add" | "remove"; lines: string[] }>
  ): string {
    const ops = precomputedOps ?? this.diffLines(a, b);
    const header = [`--- a/${relPath}`, `+++ b/${relPath}`];
    const body: string[] = [];
    for (const op of ops) {
      for (const line of op.lines) {
        if (body.length >= maxLines) break;
        if (op.type === "equal") body.push(" " + line);
        else if (op.type === "add") body.push("+" + line);
        else body.push("-" + line);
      }
      if (body.length >= maxLines) break;
    }
    return header.concat(body).join("\n");
  }
}

=== src/agent/run.ts ===
import path from "node:path";
import fs from "node:fs";
import { spawnSync } from "node:child_process";

import { openai } from "../openai.ts";
import { AgentLogger } from "./log.ts";
import { RepoTools } from "./tools.ts";
import { SandboxOptions, listFilesRecursive } from "./security.ts";

/**
 * Konfiguracja bezpieczeństwa repo sandbox.
 */
export function defaultSandboxOptions(repoRoot: string): SandboxOptions {
  return {
    repoRoot,
    denyDirs: [".git", "node_modules", "dist"],
    denyFilesExact: [".env"],
    denyExtensions: [".pem", ".key"],
    maxReadBytes: 400_000,
    maxWriteBytes: 800_000,
  };
}

export type AgentRunOptions = {
  repoRoot: string;
  task: string;
  model?: string; // np. "gpt-5"
  maxToolCalls?: number; // domyślnie 50
};

function nowIso() {
  return new Date().toISOString();
}

function safeGitDiff(repoRoot: string): { ok: boolean; diff?: string; error?: string } {
  // Jedyna “komenda systemowa” jaką wykonujemy: git diff
  const res = spawnSync("git", ["diff"], {
    cwd: repoRoot,
    shell: false,
    encoding: "utf8",
  });

  if (res.status !== 0) {
    return { ok: false, error: `${res.stdout}\n${res.stderr}`.trim() };
  }
  return { ok: true, diff: res.stdout ?? "" };
}

function buildSystemPrompt(repoRoot: string) {
  // Zawsze wczytuj prompt z pliku: resources/promts/system-prompt.txt (relatywnie do repoRoot)
  const promptPath = path.join(repoRoot, "resources", "promts", "codeAgentPromt.txt");
  if (!fs.existsSync(promptPath)) {
    throw new Error(`Brak pliku promptu: ${promptPath}`);
  }
  const content = fs.readFileSync(promptPath, "utf8");
  const normalized = (content ?? "").replace(/\r\n/g, "\n").trim();
  if (!normalized) {
    throw new Error(`Plik promptu jest pusty: ${promptPath}`);
  }
  return normalized;
}

/**
 * Tworzy snapshot bazowy repozytorium na potrzeby review.
 * Zapisuje .agent_baseline.json w katalogu głównym repo.
 */
function createBaseline(opts: SandboxOptions): { path: string; files: number } {
  const repoRoot = path.resolve(opts.repoRoot);
  const baselinePath = path.join(repoRoot, ".agent_baseline.json");

  const files = listFilesRecursive(opts, 5000);
  const data: any = {
    createdAt: nowIso(),
    maxReadBytes: opts.maxReadBytes,
    files: {} as Record<string, { bytes: number; content: string | null }>,
  };

  for (const rel of files) {
    try {
      const abs = path.join(repoRoot, rel.replaceAll("/", path.sep));
      const st = fs.statSync(abs);
      if (!st.isFile()) continue;
      if (st.size <= opts.maxReadBytes) {
        const content = fs.readFileSync(abs, "utf8");
        data.files[rel] = { bytes: st.size, content };
      } else {
        data.files[rel] = { bytes: st.size, content: null };
      }
    } catch {
      // pomiń pliki, których nie da się odczytać
    }
  }

  fs.writeFileSync(baselinePath, JSON.stringify(data, null, 2), "utf8");
  return { path: baselinePath, files: Object.keys(data.files).length };
}

/**
 * Agent loop z tool calling.
 *
 * WAŻNE:
 * - Używamy previous_response_id, więc NIE odsyłamy function_call itemów z powrotem w input,
 *   bo mają id (fc_...) i API zwraca 400 Duplicate item found.
 * - Odsyłamy tylko function_call_output z call_id.
 */
export async function runAgent(opts: AgentRunOptions): Promise<void> {
  const repoRoot = path.resolve(opts.repoRoot);
  const task = opts.task.trim();
  const model = opts.model ?? "gpt-5";
  const maxToolCalls = Math.max(1, Math.min(opts.maxToolCalls ?? 50, 50));

  const logger = new AgentLogger(repoRoot);
  logger.initNewRun({ task, model, startedAt: nowIso() });

  const sandbox = defaultSandboxOptions(repoRoot);

  // Utwórz snapshot bazowy dla funkcji review
  try {
    const b = createBaseline(sandbox);
    logger.appendJSON({ type: "baseline_created", at: nowIso(), path: b.path, files: b.files });
  } catch (e: any) {
    logger.appendJSON({ type: "baseline_error", at: nowIso(), error: e?.message ?? String(e) });
  }

  const tools = new RepoTools(sandbox);

  logger.appendJSON({ type: "model_request", at: nowIso(), model, phase: "initial" });

  // Pierwsze wywołanie: system + user
  let response = await openai.responses.create({
    model,
    tools: tools.getToolSpecs() as any,
    input: [
      { role: "system", content: buildSystemPrompt(repoRoot) },
      { role: "user", content: task },
    ],
  });

  let toolCallsUsed = 0;

  while (true) {
    const outputItems: any[] = (response as any).output ?? [];

    logger.appendJSON({
      type: "model_response",
      at: nowIso(),
      id: (response as any).id,
      output_text: (response as any).output_text ?? "",
      output: outputItems,
    });

    const functionCalls = outputItems.filter((it) => it?.type === "function_call");

    // Jeśli model nie woła narzędzi, kończymy
    if (functionCalls.length === 0) break;

    const nextInput: any[] = [];

    for (const item of functionCalls) {
      toolCallsUsed++;
      if (toolCallsUsed > maxToolCalls) {
        throw new Error(`Tool call limit exceeded (${maxToolCalls}).`);
      }

      const name = item.name as any;
      const callId = item.call_id;
      const argsRaw = item.arguments ?? "{}";

      logger.appendJSON({
        type: "tool_call",
        at: nowIso(),
        call_id: callId,
        name,
        arguments: argsRaw,
      });

      let args: any = {};
      try {
        args = typeof argsRaw === "string" ? JSON.parse(argsRaw) : argsRaw;
      } catch {
        args = {};
      }

      const result = await tools.dispatch({ name, arguments: args } as any);

      logger.appendJSON({
        type: "tool_result",
        at: nowIso(),
        call_id: callId,
        name,
        ok: result.ok,
        error: result.error,
        result_preview:
          result.result && typeof result.result === "object"
            ? JSON.stringify(result.result).slice(0, 5000)
            : String(result.result ?? "").slice(0, 5000),
      });

      // Odsyłamy TYLKO output narzędzia
      nextInput.push({
        type: "function_call_output",
        call_id: callId,
        output: JSON.stringify(result),
      });
    }

    logger.appendJSON({
      type: "model_request",
      at: nowIso(),
      model,
      phase: "followup",
      tool_calls_used: toolCallsUsed,
      followup_items: nextInput.length,
    });

    response = await openai.responses.create({
      model,
      tools: tools.getToolSpecs() as any,
      previous_response_id: (response as any).id,
      input: nextInput,
    });
  }

  // Po zakończeniu agent loop: generujemy lokalnie agent.diff.txt (bez udziału modelu)
  const diffRes = safeGitDiff(repoRoot);
  if (diffRes.ok) {
    const out = logger.saveDiffText(diffRes.diff ?? "");
    logger.appendLine(`=== SAVED DIFF: ${out} ===`);
  } else {
    logger.appendLine("=== WARNING: git diff failed (repo may not be git). Diff omitted. ===");
    logger.appendJSON({ type: "git_diff_error", at: nowIso(), error: diffRes.error });
  }

  logger.appendLine("=== AGENT RUN END ===");
}
